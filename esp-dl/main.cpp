#include <stdio.h>
#include <stdlib.h>
#include <cstring>
#include <vector>
#include <cmath>
#include <complex>
#include <algorithm>

// ESP-IDF Drivers
#include "freertos/FreeRTOS.h"
#include "freertos/task.h"
#include "driver/i2s.h"
#include "esp_log.h"
#include "esp_timer.h"

// ESP-DL / PPQ Generated Model Headers
// IMPORTANT: These files are generated by the esp-ppq tool script
#include "dl_tool.hpp"
#include "model_define.hpp" // Contains your specific Model class wrapper

static const char *TAG = "KWS_STREAMING";

// =================================================================================
// 1. CONFIGURATION (Must match main3.py)
// =================================================================================

// Hardware Config (Adjust for your specific board, e.g., ESP32-S3-Korvo)
#define I2S_NUM         I2S_NUM_0
#define I2S_BCK_PIN     41
#define I2S_WS_PIN      42
#define I2S_DATA_IN_PIN 40
#define SAMPLE_RATE     16000

// Audio Preprocessing Config
#define FRAME_SIZE_MS   32    // Window size
#define HOP_SIZE_MS     20    // 20ms streaming update
#define N_MELS          40    // Mel bins
#define N_FFT           512

// Model Config
// The model expects a specific time context (e.g., 64 frames â‰ˆ 1.2s)
// Check your ONNX input shape: [1, 1, 40, T]
#define MODEL_INPUT_FRAMES 64 

// Derived
#define HOP_SAMPLES    (SAMPLE_RATE * HOP_SIZE_MS / 1000) // 320
#define WIN_SAMPLES    (SAMPLE_RATE * FRAME_SIZE_MS / 1000) // 512

// =================================================================================
// 2. AUDIO FRONT END (Bit-Exact to Training)
// =================================================================================

class AudioFrontEnd {
private:
    std::vector<float> window_;
    std::vector<std::vector<float>> mel_filters_;
    std::vector<int16_t> input_buffer_; // Holds raw audio for windowing
    
    // Simple FFT (Consider replacing with dsps_fft2r_fc32 from esp-dsp for speed)
    void fft(std::vector<std::complex<float>>& x) {
        size_t n = x.size();
        if (n <= 1) return;
        std::vector<std::complex<float>> even(n / 2), odd(n / 2);
        for (size_t i = 0; i < n / 2; ++i) {
            even[i] = x[2 * i];
            odd[i] = x[2 * i + 1];
        }
        fft(even);
        fft(odd);
        for (size_t i = 0; i < n / 2; ++i) {
            std::complex<float> t = std::polar(1.0f, (float)(-2.0f * M_PI * i / n)) * odd[i];
            x[i] = even[i] + t;
            x[i + n / 2] = even[i] - t;
        }
    }

    void init_hann_window() {
        window_.resize(WIN_SAMPLES);
        for (int i = 0; i < WIN_SAMPLES; ++i) {
            window_[i] = 0.5f * (1.0f - cosf(2.0f * M_PI * i / (WIN_SAMPLES - 1)));
        }
    }

    void init_mel_filters() {
        // Hardcoded or computed. For full dynamic Slaney generation, 
        // copy the 'create_mel_filters' function from the previous C++ response.
        // Here we assume it is initialized or loaded. 
        // Ideally, export the filterbank as a float array from Python to save startup time.
        
        // PLACEHOLDER: Ensure you copy the 'create_mel_filters' logic here!
        mel_filters_.resize(N_MELS, std::vector<float>(N_FFT / 2 + 1, 0.0f));
        // ... (Insert filter generation code here) ...
    }

public:
    AudioFrontEnd() {
        init_hann_window();
        init_mel_filters(); // Don't forget to populate this!
        input_buffer_.reserve(WIN_SAMPLES);
    }

    // Takes ~320 samples, returns 1 vector of 40 Mel features
    bool process_20ms_step(const int16_t* new_audio, std::vector<float>& out_mels) {
        // 1. Buffer Management
        input_buffer_.insert(input_buffer_.end(), new_audio, new_audio + HOP_SAMPLES);
        
        if (input_buffer_.size() < WIN_SAMPLES) {
            // Wait until we have enough for a full window (cold start)
            return false; 
        }

        // 2. Prepare Window (Last WIN_SAMPLES)
        size_t start_idx = input_buffer_.size() - WIN_SAMPLES;
        std::vector<std::complex<float>> spectrum(N_FFT, 0.0f);
        
        for (int i = 0; i < WIN_SAMPLES; ++i) {
            float sample = (float)input_buffer_[start_idx + i] / 32768.0f;
            spectrum[i] = sample * window_[i];
        }

        // 3. FFT & Power Spec
        fft(spectrum);
        
        // 4. Mel Filterbank & Log
        out_mels.assign(N_MELS, 0.0f);
        for (int i = 0; i < N_MELS; ++i) {
            float energy = 0.0f;
            for (int j = 0; j < N_FFT / 2 + 1; ++j) {
                float mag_sq = std::norm(spectrum[j]) / N_FFT; // norm returns real^2 + imag^2
                energy += mag_sq * mel_filters_[i][j];
            }
            // Log10 + epsilon
            out_mels[i] = 10.0f * log10f(energy + 1e-6f);
        }

        // 5. Shift Buffer (Remove old HOP_SAMPLES)
        input_buffer_.erase(input_buffer_.begin(), input_buffer_.begin() + HOP_SAMPLES);
        
        return true;
    }
};

// =================================================================================
// 3. MAIN APPLICATION
// =================================================================================

extern "C" void app_main(void) {
    // 1. Setup I2S
    i2s_config_t i2s_config = {
        .mode = (i2s_mode_t)(I2S_MODE_MASTER | I2S_MODE_RX),
        .sample_rate = SAMPLE_RATE,
        .bits_per_sample = I2S_BITS_PER_SAMPLE_16BIT,
        .channel_format = I2S_CHANNEL_FMT_ONLY_LEFT,
        .communication_format = I2S_COMM_FORMAT_STAND_I2S,
        .intr_alloc_flags = ESP_INTR_FLAG_LEVEL1,
        .dma_buf_count = 4,
        .dma_buf_len = HOP_SAMPLES, // Interrupt every 20ms
        .use_apll = false,
    };
    i2s_driver_install(I2S_NUM, &i2s_config, 0, NULL);
    i2s_set_pin(I2S_NUM, NULL); // Use default or set custom pins struct

    // 2. Initialize Processing
    AudioFrontEnd afe;
    // Buffer to hold the Model's context (e.g., [40 x 64])
    // We treat this as a flattened circular buffer or shift manually
    std::vector<float> feature_history(N_MELS * MODEL_INPUT_FRAMES, 0.0f);
    
    // 3. Initialize Model (Wrapper generated by ESP-PPQ)
    // The class name 'BCResNet' depends on your ONNX model name
    BCResNet model; 
    
    ESP_LOGI(TAG, "System Initialized. Listening...");

    int16_t raw_audio[HOP_SAMPLES];
    std::vector<float> current_mels(N_MELS);
    size_t bytes_read;

    while (1) {
        // A. Read 20ms Audio
        i2s_read(I2S_NUM, raw_audio, sizeof(raw_audio), &bytes_read, portMAX_DELAY);

        // B. Compute Features
        if (afe.process_20ms_step(raw_audio, current_mels)) {
            
            // C. Update History (Sliding Window)
            // Shift everything left by 1 column (N_MELS)
            // Note: Optimizing this to a ring buffer is better for perf, 
            // but memmove is safe and clear for logic.
            size_t history_size = feature_history.size();
            size_t step_size = N_MELS;
            
            // Shift: Dst, Src, Size
            memmove(feature_history.data(), 
                    feature_history.data() + step_size, 
                    (history_size - step_size) * sizeof(float));
            
            // Copy new col to end
            memcpy(feature_history.data() + (history_size - step_size), 
                   current_mels.data(), 
                   step_size * sizeof(float));

            // D. Run Inference
            // esp-ppq models usually take inputs via the `input` tensor member
            // Check model_define.hpp for exact input name (often 'input' or 'input_1')
            // Reshape is usually handled by the model definition, we just copy data.
            
            Tensor<float> input_tensor; 
            input_tensor.set_element((float *)feature_history.data())
                        .set_shape({1, 1, N_MELS, MODEL_INPUT_FRAMES}) // NCHW or similar
                        .set_auto_free(false); // We manage memory

            // Execute
            model.run(&input_tensor); 

            // E. Get Result
            // Access output map (check generated header for key name)
            Tensor<float> *output = model.get_output("output"); 
            
            if (output) {
                float *probs = output->get_element_ptr();
                // Assuming index 1 is 'Keyword Detected'
                float score = probs[1]; 
                
                if (score > 0.85f) {
                    ESP_LOGI(TAG, "WAKEWORD DETECTED! (Score: %.2f)", score);
                }
            }
        }
    }
}
