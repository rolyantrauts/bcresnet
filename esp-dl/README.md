Do not use the bcresnet_int8.onnx (this is for generic Linux/Windows/Mac CPUs).  
Use the bcresnet_float32.onnx generated by your training.  
Convert it using Espressif's tool (ESP-PPQ) to create the .espdl file.  
BCResNet on ESP-DL1.   
Operator Compatibility ESP-DL Supported Operators list.  
BCResNet LayerONNX OperatorESP-DL SupportNotesConv2DConv✅ SupportedHighly optimized on ESP32-S3 (uses vector instructions).  
BatchNormBatchNormalization✅ SupportedUsually fused into Conv during conversion.  
ReLURelu✅ Supported  
AdaptiveAvgPoolGlobalAveragePool✅ Supported Used in the final layer.  
AddAdd✅ SupportedUsed for the Residual connections.  
FlattenFlatten✅ Supported  
Sub-Spectral NormReshape / Trans✅ SupportedSSN relies on reshaping tensors. ESP-DL supports Reshape and Transpose.

Potential Issue: The "1D Branch" of BCResNet uses AdaptiveAvgPool2d((1, None)).

This pools the Frequency height to 1 but keeps the Time width.

Verdict: This should export as a standard AveragePool with a rectangular kernel (e.g., kernel_size=(5, 1)). ESP-DL supports 2D pooling, so this should work.

2. The Conversion Workflow (New Step Required)
You need to set up ESP-PPQ, which is Espressif's quantization tool. It takes your Float32 ONNX model + a few calibration audio files and produces the .espdl file.

Step A: Install ESP-PPQ

```
pip install esp-ppq
```

Added and example quantize_for_esp.py that Gemma3 pro kindly provided haven't tested as my sexuality is Pi.
Someone might want to give it a try with BcResnet being SoTa in accuracy but also in reduced model size and compute.
Recommendation
Stick to ESP32-S3: The S3 chip has vector instructions (AI acceleration) that speeds up the Conv2D layers in BCResNet significantly. The classic ESP32 will struggle with an 80-Mel BCResNet.

Use the Float32 ONNX: Ignore the int8 file generated by main.py. It uses a generic quantization format that esp-dl cannot read.

Update main.py Export: In your main.py, ensure your ONNX export uses opset_version=13. ESP-DL sometimes struggles with newer opsets (17).

Change: opset_version=13 in torch.onnx.export.
